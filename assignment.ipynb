{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7SXpaKwwGe5x"
   },
   "source": [
    "# TM10007 Assignment template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "CiDn2Sk-VWqE",
    "outputId": "64224cd2-6054-4b04-a3f6-af8290400dfc"
   },
   "outputs": [],
   "source": [
    "# Run this to use from colab environment\n",
    "#!pip install -q --upgrade git+https://github.com/jveenland/tm10007_ml.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and cleaning\n",
    "\n",
    "Below are functions to load the dataset of your choice. After that, it is all up to you to create and evaluate a classification method. Beware, there may be missing values in these datasets. Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-NE_fTbKGe5z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of samples: 115\n",
      "The number of columns: 494\n",
      "The number of liposarcoma in the dataset: 58\n",
      "The number of lipoma in the dataset: 57\n"
     ]
    }
   ],
   "source": [
    "# Data loading functions. Uncomment the one you want to use\n",
    "# Import other classifiers you plan to use\n",
    "from worclipo.load_data import load_data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn import preprocessing\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = load_data()\n",
    "print(f\"The number of samples: {len(data.index)}\")\n",
    "print(f\"The number of columns: {len(data.columns)}\")\n",
    "print(f\"The number of liposarcoma in the dataset: {len(data[data['label'] == 'liposarcoma'])}\")\n",
    "print(f\"The number of lipoma in the dataset: {len(data[data['label'] == 'lipoma'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''deleting all the columns consisting of only 0's'''\n",
    "\n",
    "# find the column that contains only zeros\n",
    "zero_columns = data.columns[data.eq(0).all()]\n",
    "\n",
    "# Drop columns with only zeros\n",
    "data_whithout_0 = data.drop(zero_columns, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know the number of samples, colums and labels. The next step is to look for missing data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (92, 480)\n",
      "Testing set size: (23, 480)\n"
     ]
    }
   ],
   "source": [
    "def split_data(data_whithout_0):\n",
    "\n",
    "    # Separate features and target variable\n",
    "    x = data_whithout_0.drop(['label'], axis=1)\n",
    "    y = data_whithout_0['label']\n",
    "    \n",
    "    # Split the dataset into training and testing sets\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "\n",
    "# Call the function\n",
    "x_train, x_test, y_train, y_test = split_data(data_whithout_0)\n",
    "\n",
    "# Optionally, print the sizes of the splits to verify\n",
    "print(\"Training set size:\", x_train.shape)\n",
    "print(\"Testing set size:\", x_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\31642\\AppData\\Local\\Temp\\ipykernel_2476\\50788196.py:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '1.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  x_train.loc[x_train[feature] < lower_bound, feature] = lower_bound\n",
      "C:\\Users\\31642\\AppData\\Local\\Temp\\ipykernel_2476\\50788196.py:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '15.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  x_train.loc[x_train[feature] < lower_bound, feature] = lower_bound\n",
      "C:\\Users\\31642\\AppData\\Local\\Temp\\ipykernel_2476\\50788196.py:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '18.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  x_train.loc[x_train[feature] < lower_bound, feature] = lower_bound\n",
      "C:\\Users\\31642\\AppData\\Local\\Temp\\ipykernel_2476\\50788196.py:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '19.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  x_train.loc[x_train[feature] < lower_bound, feature] = lower_bound\n",
      "C:\\Users\\31642\\AppData\\Local\\Temp\\ipykernel_2476\\50788196.py:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '13.625' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  x_train.loc[x_train[feature] < lower_bound, feature] = lower_bound\n",
      "C:\\Users\\31642\\AppData\\Local\\Temp\\ipykernel_2476\\50788196.py:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '8.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  x_train.loc[x_train[feature] < lower_bound, feature] = lower_bound\n",
      "C:\\Users\\31642\\AppData\\Local\\Temp\\ipykernel_2476\\50788196.py:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '17.125' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  x_train.loc[x_train[feature] < lower_bound, feature] = lower_bound\n",
      "C:\\Users\\31642\\AppData\\Local\\Temp\\ipykernel_2476\\50788196.py:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '17.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  x_train.loc[x_train[feature] < lower_bound, feature] = lower_bound\n",
      "C:\\Users\\31642\\AppData\\Local\\Temp\\ipykernel_2476\\50788196.py:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '9.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  x_train.loc[x_train[feature] < lower_bound, feature] = lower_bound\n",
      "C:\\Users\\31642\\AppData\\Local\\Temp\\ipykernel_2476\\50788196.py:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '9.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  x_train.loc[x_train[feature] < lower_bound, feature] = lower_bound\n",
      "C:\\Users\\31642\\AppData\\Local\\Temp\\ipykernel_2476\\50788196.py:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '10.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  x_train.loc[x_train[feature] < lower_bound, feature] = lower_bound\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2211 outliers were replaced.\n",
      "This was 4% of the total amount of datapoints.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\31642\\AppData\\Local\\Temp\\ipykernel_2476\\50788196.py:13: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '-29.375' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  x_train.loc[x_train[feature] < lower_bound, feature] = lower_bound\n"
     ]
    }
   ],
   "source": [
    "outliers_total = 0\n",
    "\n",
    "for feature in x_train.columns:\n",
    "    q1 = x_train[feature].quantile(0.25)\n",
    "    q3 = x_train[feature].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - (1.5 * iqr)\n",
    "    upper_bound = q3 + (1.5 * iqr)\n",
    "\n",
    "    outliers_column = (x_train[feature] < lower_bound).sum() + (x_train[feature] > upper_bound).sum()\n",
    "    outliers_total += outliers_column\n",
    "\n",
    "    x_train.loc[x_train[feature] < lower_bound, feature] = lower_bound\n",
    "    x_train.loc[x_train[feature] > upper_bound, feature] = upper_bound\n",
    "\n",
    "print(f\"{outliers_total} outliers were replaced.\")\n",
    "print(f\"This was {round(outliers_total / (len(data.index) * len(data.columns)) *100)}% of the total amount of datapoints.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling_data(x_train,x_test):\n",
    "    scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "\n",
    "    # Applying scaler to train and test set\n",
    "    X_train_scaled = pd.DataFrame(scaler.transform(x_train), index=x_train.index, columns=x_train.columns)\n",
    "    X_test_scaled = pd.DataFrame(scaler.transform(x_test), index=x_test.index, columns=x_test.columns)\n",
    "\n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "X_train_scaled, X_test_scaled = scaling_data(x_train, x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\31642\\AppData\\Local\\Temp\\ipykernel_2476\\1666009437.py:11: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  gaussian_test = pd.concat([gaussian_test, feature_result])\n",
      "c:\\Users\\31642\\miniconda3\\Lib\\site-packages\\scipy\\stats\\_morestats.py:1879: UserWarning: Input data for shapiro has range zero. The results may not be accurate.\n",
      "  warnings.warn(\"Input data for shapiro has range zero. The results \"\n",
      "c:\\Users\\31642\\miniconda3\\Lib\\site-packages\\scipy\\stats\\_morestats.py:1879: UserWarning: Input data for shapiro has range zero. The results may not be accurate.\n",
      "  warnings.warn(\"Input data for shapiro has range zero. The results \"\n",
      "c:\\Users\\31642\\miniconda3\\Lib\\site-packages\\scipy\\stats\\_morestats.py:1879: UserWarning: Input data for shapiro has range zero. The results may not be accurate.\n",
      "  warnings.warn(\"Input data for shapiro has range zero. The results \"\n",
      "c:\\Users\\31642\\miniconda3\\Lib\\site-packages\\scipy\\stats\\_morestats.py:1879: UserWarning: Input data for shapiro has range zero. The results may not be accurate.\n",
      "  warnings.warn(\"Input data for shapiro has range zero. The results \"\n",
      "c:\\Users\\31642\\miniconda3\\Lib\\site-packages\\scipy\\stats\\_morestats.py:1879: UserWarning: Input data for shapiro has range zero. The results may not be accurate.\n",
      "  warnings.warn(\"Input data for shapiro has range zero. The results \"\n",
      "c:\\Users\\31642\\miniconda3\\Lib\\site-packages\\scipy\\stats\\_morestats.py:1879: UserWarning: Input data for shapiro has range zero. The results may not be accurate.\n",
      "  warnings.warn(\"Input data for shapiro has range zero. The results \"\n",
      "c:\\Users\\31642\\miniconda3\\Lib\\site-packages\\scipy\\stats\\_morestats.py:1879: UserWarning: Input data for shapiro has range zero. The results may not be accurate.\n",
      "  warnings.warn(\"Input data for shapiro has range zero. The results \"\n",
      "c:\\Users\\31642\\miniconda3\\Lib\\site-packages\\scipy\\stats\\_morestats.py:1879: UserWarning: Input data for shapiro has range zero. The results may not be accurate.\n",
      "  warnings.warn(\"Input data for shapiro has range zero. The results \"\n",
      "c:\\Users\\31642\\miniconda3\\Lib\\site-packages\\scipy\\stats\\_morestats.py:1879: UserWarning: Input data for shapiro has range zero. The results may not be accurate.\n",
      "  warnings.warn(\"Input data for shapiro has range zero. The results \"\n",
      "c:\\Users\\31642\\miniconda3\\Lib\\site-packages\\scipy\\stats\\_morestats.py:1879: UserWarning: Input data for shapiro has range zero. The results may not be accurate.\n",
      "  warnings.warn(\"Input data for shapiro has range zero. The results \"\n",
      "c:\\Users\\31642\\miniconda3\\Lib\\site-packages\\scipy\\stats\\_morestats.py:1879: UserWarning: Input data for shapiro has range zero. The results may not be accurate.\n",
      "  warnings.warn(\"Input data for shapiro has range zero. The results \"\n",
      "c:\\Users\\31642\\miniconda3\\Lib\\site-packages\\scipy\\stats\\_morestats.py:1879: UserWarning: Input data for shapiro has range zero. The results may not be accurate.\n",
      "  warnings.warn(\"Input data for shapiro has range zero. The results \"\n",
      "c:\\Users\\31642\\miniconda3\\Lib\\site-packages\\scipy\\stats\\_morestats.py:1879: UserWarning: Input data for shapiro has range zero. The results may not be accurate.\n",
      "  warnings.warn(\"Input data for shapiro has range zero. The results \"\n",
      "c:\\Users\\31642\\miniconda3\\Lib\\site-packages\\scipy\\stats\\_morestats.py:1879: UserWarning: Input data for shapiro has range zero. The results may not be accurate.\n",
      "  warnings.warn(\"Input data for shapiro has range zero. The results \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322 features are not gaussian distributed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\31642\\miniconda3\\Lib\\site-packages\\scipy\\stats\\_morestats.py:1879: UserWarning: Input data for shapiro has range zero. The results may not be accurate.\n",
      "  warnings.warn(\"Input data for shapiro has range zero. The results \"\n",
      "c:\\Users\\31642\\miniconda3\\Lib\\site-packages\\scipy\\stats\\_morestats.py:1879: UserWarning: Input data for shapiro has range zero. The results may not be accurate.\n",
      "  warnings.warn(\"Input data for shapiro has range zero. The results \"\n",
      "c:\\Users\\31642\\miniconda3\\Lib\\site-packages\\scipy\\stats\\_morestats.py:1879: UserWarning: Input data for shapiro has range zero. The results may not be accurate.\n",
      "  warnings.warn(\"Input data for shapiro has range zero. The results \"\n",
      "c:\\Users\\31642\\miniconda3\\Lib\\site-packages\\scipy\\stats\\_morestats.py:1879: UserWarning: Input data for shapiro has range zero. The results may not be accurate.\n",
      "  warnings.warn(\"Input data for shapiro has range zero. The results \"\n",
      "c:\\Users\\31642\\miniconda3\\Lib\\site-packages\\scipy\\stats\\_morestats.py:1879: UserWarning: Input data for shapiro has range zero. The results may not be accurate.\n",
      "  warnings.warn(\"Input data for shapiro has range zero. The results \"\n",
      "c:\\Users\\31642\\miniconda3\\Lib\\site-packages\\scipy\\stats\\_morestats.py:1879: UserWarning: Input data for shapiro has range zero. The results may not be accurate.\n",
      "  warnings.warn(\"Input data for shapiro has range zero. The results \"\n",
      "c:\\Users\\31642\\miniconda3\\Lib\\site-packages\\scipy\\stats\\_morestats.py:1879: UserWarning: Input data for shapiro has range zero. The results may not be accurate.\n",
      "  warnings.warn(\"Input data for shapiro has range zero. The results \"\n"
     ]
    }
   ],
   "source": [
    "'''checking if train-set is normally distributed'''\n",
    "lipoma = X_train_scaled[y_train =='lipoma']\n",
    "liposarcoma = X_train_scaled[y_train =='liposarcoma']\n",
    "alpha = 0.05\n",
    "non_gaussian = 0\n",
    "\n",
    "gaussian_test = pd.DataFrame(columns=['statistic', 'p_value'])\n",
    "for feature in lipoma.columns:\n",
    "    statistic, p_value = stats.shapiro(lipoma[feature])\n",
    "    feature_result = pd.DataFrame({'statistic': statistic, 'p_value': p_value}, index = [feature])\n",
    "    gaussian_test = pd.concat([gaussian_test, feature_result])\n",
    "    if p_value < alpha:\n",
    "        non_gaussian += 1\n",
    "        \n",
    "print(f\"{non_gaussian} features are not gaussian distributed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\31642\\AppData\\Local\\Temp\\ipykernel_2476\\2390329497.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  mwu_result = pd.concat([mwu_result, feature_result])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92, 106)\n"
     ]
    }
   ],
   "source": [
    "def manual_feature_selection_ttest(X_train_scaled, y_train):\n",
    "    '''defiition to calculate the Ttest and P-value of every feature\n",
    "    input: x_train, y_train\n",
    "    output: beste 5 festures'''\n",
    "    \n",
    "    lipoma = X_train_scaled[y_train =='lipoma']\n",
    "    liposarcoma = X_train_scaled[y_train =='liposarcoma']\n",
    "\n",
    "    mwu_result = pd.DataFrame(columns=['statistic', 'p_value'])\n",
    "    for feature in X_train_scaled.columns:\n",
    "        statistic, p_value = stats.mannwhitneyu(lipoma[feature], liposarcoma[feature])\n",
    "        feature_result = pd.DataFrame({'statistic': statistic, 'p_value': p_value}, index = [feature])\n",
    "        mwu_result = pd.concat([mwu_result, feature_result])\n",
    "    return mwu_result\n",
    "\n",
    "def select_features_by_p_value(mwu_result, alpha=0.05):\n",
    "    '''Definition to select features based on p-value threshold of 0.05'''\n",
    "\n",
    "    selected_features = mwu_result[mwu_result['p_value'] < alpha].index\n",
    "    selected_features_df = X_train_scaled[selected_features]\n",
    "    \n",
    "    return selected_features_df\n",
    "\n",
    "mwu_result = manual_feature_selection_ttest(X_train_scaled, y_train)\n",
    "selected_features_df = select_features_by_p_value(mwu_result, alpha=0.05)\n",
    "\n",
    "print(selected_features_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total explained variance ratio: 0.8892339898767037\n",
      "Number of components: 15\n",
      "Eigenvalues: [45.22924742 13.34463068  5.76533108  5.65849508  4.37244717  3.463253\n",
      "  2.7191931   2.55669258  2.45321094  2.25748286  1.86365488  1.767562\n",
      "  1.43948072  1.22143522  1.18249722]\n"
     ]
    }
   ],
   "source": [
    "def apply_pca_with_variance(X, min_variance):\n",
    "    '''Definition to apply PCA for dimensionality reduction until a desired variance is achieved'''\n",
    "    \n",
    "    pca = PCA()\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    explained_variance_ratios = pca.explained_variance_ratio_\n",
    "    \n",
    "    # Accumulate explained variances until reaching the desired threshold\n",
    "    cumulative_variance_ratio = 0.0\n",
    "    n_components = 0\n",
    "    for variance_ratio in explained_variance_ratios:\n",
    "        cumulative_variance_ratio += variance_ratio\n",
    "        n_components += 1\n",
    "        if cumulative_variance_ratio >= min_variance:\n",
    "            break\n",
    "    \n",
    "    # Fit PCA again with the selected number of components\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    X_pca_df = pd.DataFrame(X_pca)\n",
    "\n",
    "    # Print the total explained variance ratio and the number of components\n",
    "    print(\"Total explained variance ratio:\", cumulative_variance_ratio)\n",
    "    print(\"Number of components:\", n_components)\n",
    "\n",
    "    # Obtain eigenvalues\n",
    "    eigenvalues = pca.explained_variance_\n",
    "    print(\"Eigenvalues:\", eigenvalues)\n",
    "    return X_pca_df\n",
    "\n",
    "min_variance_ratio = 0.88  # 89% of the total explained variance ratio\n",
    "X_pca_df = apply_pca_with_variance(selected_features_df, min_variance_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifiers \n",
    "\n",
    "- decision trees\n",
    "- naive bayes\n",
    "- linear classifiers\n",
    "- quadratic classifiers\n",
    "- ⁠nearest neighbour\n",
    "- random forrest \n",
    "- ⁠support vector machines\n",
    "- neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rfc = RandomForestClassifier()\n",
    "param_grid = {\n",
    "    'n_estimators': range(10, 311, 100),  # Number of trees in the forest\n",
    "    'max_depth': range(10,51,10),      # Maximum depth of the trees\n",
    "    'min_samples_split': range(2,11,4),  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': range(1,14,4)}  # Minimum number of samples required to be at a leaf node\n",
    "\n",
    "grid_search = GridSearchCV(estimator=clf_rfc, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_pca_df, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
    "print(f\"Best accuracy score: {grid_search.best_score_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'C': 1, 'degree': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "Best accuracy score: 0.6964912280701755\n"
     ]
    }
   ],
   "source": [
    "clf_svm = SVC()\n",
    "\n",
    "param_grid = {'C': [0.1, 1, 10, 100],\n",
    "              'gamma': [1, 0.1, 0.01, 0.001],\n",
    "              'kernel': ['rbf', 'linear', 'poly'],\n",
    "              'degree': [1, 3, 5]}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=clf_svm, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_pca_df, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
    "print(f\"Best accuracy score: {grid_search.best_score_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "keyword argument repeated: scoring (1161625407.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[91], line 8\u001b[1;36m\u001b[0m\n\u001b[1;33m    grid_search = GridSearchCV(estimator=clf_knn, param_grid=param_grid, cv=5, scoring='accuracy', scoring='recall', n_jobs=-1)\u001b[0m\n\u001b[1;37m                                                                                                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m keyword argument repeated: scoring\n"
     ]
    }
   ],
   "source": [
    "clf_knn = KNeighborsClassifier()\n",
    "\n",
    "param_grid = {'n_neighbors': [3, 5, 7, 9],\n",
    "              'weights': ['uniform', 'distance'],\n",
    "              'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "              'p': [1, 2]}  # 1 for Manhattan distance, 2 for Euclidean distance\n",
    "\n",
    "grid_search = GridSearchCV(estimator=clf_knn, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_pca_df, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
    "print(f\"Best accuracy score: {grid_search.best_score_}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 5}\n",
      "Best accuracy score: 0.7619883040935673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\31642\\miniconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "360 fits failed out of a total of 1080.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "271 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\31642\\miniconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\31642\\miniconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\31642\\miniconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\31642\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of DecisionTreeClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "89 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\31642\\miniconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\31642\\miniconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\31642\\miniconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\31642\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of DecisionTreeClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\31642\\miniconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.74152047 0.70877193 0.65204678\n",
      " 0.68538012 0.63040936 0.61929825 0.62982456 0.72865497 0.72982456\n",
      " 0.69649123 0.71812865 0.70643275 0.66315789 0.71754386 0.73918129\n",
      " 0.69532164 0.69532164 0.66374269        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.74035088 0.6871345  0.68538012 0.67426901 0.69766082 0.69649123\n",
      " 0.65263158 0.65204678 0.64093567 0.65204678 0.67309942 0.68421053\n",
      " 0.71754386 0.72865497 0.66374269 0.71812865 0.67368421 0.67368421\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.67368421 0.65263158 0.61988304\n",
      " 0.74035088 0.69707602 0.6625731  0.71637427 0.64035088 0.7619883\n",
      " 0.70584795 0.65438596 0.74093567 0.68654971 0.66315789 0.72982456\n",
      " 0.73099415 0.70701754 0.70584795        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.66374269 0.68538012 0.65321637 0.66315789 0.73976608 0.64210526\n",
      " 0.69532164 0.68421053 0.65087719 0.6748538  0.68479532 0.66549708\n",
      " 0.69356725 0.70584795 0.69473684 0.69707602 0.67426901 0.6877193\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.63976608 0.76140351 0.6619883\n",
      " 0.73976608 0.68479532 0.67426901 0.69590643 0.7619883  0.59883041\n",
      " 0.71812865 0.69532164 0.69707602 0.67660819 0.62046784 0.71812865\n",
      " 0.67602339 0.72807018 0.73976608        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.6502924  0.68362573 0.69532164 0.68421053 0.64269006 0.64035088\n",
      " 0.6748538  0.75263158 0.59766082 0.60877193 0.72923977 0.70877193\n",
      " 0.69766082 0.70877193 0.68421053 0.73976608 0.70643275 0.65321637\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.66315789 0.71871345 0.69590643\n",
      " 0.74035088 0.68421053 0.65263158 0.68538012 0.66432749 0.69590643\n",
      " 0.63976608 0.63099415 0.74035088 0.70701754 0.68538012 0.68596491\n",
      " 0.60760234 0.71929825 0.66315789        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.57660819 0.61988304 0.65497076 0.69532164 0.7502924  0.63040936\n",
      " 0.73040936 0.67660819 0.64269006 0.6625731  0.72748538 0.68421053\n",
      " 0.67602339 0.71871345 0.68479532 0.65087719 0.69532164 0.66491228]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clf_dt = DecisionTreeClassifier()\n",
    "\n",
    "param_grid = {'criterion': ['gini', 'entropy'],\n",
    "              'max_depth': [None, 10, 20, 30],\n",
    "              'min_samples_split': [2, 5, 10],\n",
    "              'min_samples_leaf': [1, 2, 4],\n",
    "              'max_features': ['auto', 'sqrt', 'log2']}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=clf_dt, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_pca_df, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
    "print(f\"Best accuracy score: {grid_search.best_score_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 17\u001b[0m\n\u001b[0;32m      9\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhidden_layer_sizes\u001b[39m\u001b[38;5;124m'\u001b[39m: size_hidden_layers,\n\u001b[0;32m     10\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivation\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124midentity\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogistic\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtanh\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     11\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msolver\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlbfgs\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msgd\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     12\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.000001\u001b[39m, \u001b[38;5;241m0.00001\u001b[39m, \u001b[38;5;241m0.0001\u001b[39m, \u001b[38;5;241m0.001\u001b[39m, \u001b[38;5;241m0.01\u001b[39m],\n\u001b[0;32m     13\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minvscaling\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madaptive\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     14\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_iter\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m1001\u001b[39m,\u001b[38;5;241m100\u001b[39m)}\n\u001b[0;32m     16\u001b[0m mlp_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mclf_mlp, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m mlp_search\u001b[38;5;241m.\u001b[39mfit(df_best_5_features,y_train)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Get the best hyperparameters\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Hyperparameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid_search\u001b[38;5;241m.\u001b[39mbest_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\31642\\miniconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\31642\\miniconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\31642\\miniconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1418\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1419\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\31642\\miniconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    847\u001b[0m         clone(base_estimator),\n\u001b[0;32m    848\u001b[0m         X,\n\u001b[0;32m    849\u001b[0m         y,\n\u001b[0;32m    850\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    851\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    852\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    853\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    854\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    856\u001b[0m     )\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params), \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups))\n\u001b[0;32m    859\u001b[0m     )\n\u001b[0;32m    860\u001b[0m )\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\31642\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\31642\\miniconda3\\Lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\31642\\miniconda3\\Lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\31642\\miniconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m future\u001b[38;5;241m.\u001b[39mresult(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\31642\\miniconda3\\Lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\Users\\31642\\miniconda3\\Lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         waiter\u001b[38;5;241m.\u001b[39macquire()\n\u001b[0;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clf_mlp = MLPClassifier()\n",
    "\n",
    "# Create the hidden layer size variable\n",
    "size_hidden_layers = []\n",
    "for a in range(5,106,50):\n",
    "    for b in range(5,106,50):\n",
    "        size_hidden_layers.append((a,b))\n",
    "\n",
    "param_grid = {'hidden_layer_sizes': size_hidden_layers,\n",
    "              'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "              'solver': ['lbfgs', 'sgd','adam'],\n",
    "              'alpha': [0.000001, 0.00001, 0.0001, 0.001, 0.01],\n",
    "              'learning_rate': ['constant', 'invscaling','adaptive'],\n",
    "              'max_iter': range(100,1001,100)}\n",
    "\n",
    "mlp_search = GridSearchCV(estimator=clf_mlp, param_grid=param_grid, scoring='accuracy', n_jobs=-1, cv=5)\n",
    "mlp_search.fit(X_pca_df,y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
    "print(f\"Best accuracy score: {grid_search.best_score_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross validation"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
